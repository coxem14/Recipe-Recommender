{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer as PS\n",
    "\n",
    "import joblib\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2231142 entries, 0 to 2231141\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   Unnamed: 0   int64 \n",
      " 1   title        object\n",
      " 2   ingredients  object\n",
      " 3   directions   object\n",
      " 4   link         object\n",
      " 5   source       object\n",
      " 6   NER          object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 119.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['source'] == 'Gathered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='source', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1643098 entries, 0 to 1643097\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   Unnamed: 0   1643098 non-null  int64 \n",
      " 1   title        1643098 non-null  object\n",
      " 2   ingredients  1643098 non-null  object\n",
      " 3   directions   1643098 non-null  object\n",
      " 4   link         1643098 non-null  object\n",
      " 5   NER          1643098 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 87.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def literal_return(val):\n",
    "    try:\n",
    "        return literal_eval(val)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        return val\n",
    "\n",
    "def df_str_to_literal(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(literal_return)\n",
    "    return df[column_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, columns_list):\n",
    "    for col in columns_list:\n",
    "        df[col] = df_str_to_literal(df, col)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df(data, ['ingredients', 'directions', 'NER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>directions</th>\n",
       "      <th>link</th>\n",
       "      <th>NER</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>[1 c. firmly packed brown sugar, 1/2 c. evapor...</td>\n",
       "      <td>[In a heavy 2-quart saucepan, mix brown sugar,...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=44874</td>\n",
       "      <td>[brown sugar, milk, vanilla, nuts, butter, bit...</td>\n",
       "      <td>No-Bake Nut Cookies 1 c. firmly packed brown s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>[1 small jar chipped beef, cut up, 4 boned chi...</td>\n",
       "      <td>[Place chipped beef on bottom of baking dish.,...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=699419</td>\n",
       "      <td>[beef, chicken breasts, cream of mushroom soup...</td>\n",
       "      <td>Jewell Ball'S Chicken 1 small jar chipped beef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>[2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...</td>\n",
       "      <td>[In a slow cooker, combine all ingredients. Co...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=10570</td>\n",
       "      <td>[frozen corn, cream cheese, butter, garlic pow...</td>\n",
       "      <td>Creamy Corn 2 (16 oz.) pkg. frozen corn 1 (8 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>[1 large whole chicken, 2 (10 1/2 oz.) cans ch...</td>\n",
       "      <td>[Boil and debone chicken., Put bite size piece...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=897570</td>\n",
       "      <td>[chicken, chicken gravy, cream of mushroom sou...</td>\n",
       "      <td>Chicken Funny 1 large whole chicken 2 (10 1/2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>[1 c. peanut butter, 3/4 c. graham cracker cru...</td>\n",
       "      <td>[Combine first four ingredients and press in 1...</td>\n",
       "      <td>www.cookbooks.com/Recipe-Details.aspx?id=659239</td>\n",
       "      <td>[peanut butter, graham cracker crumbs, butter,...</td>\n",
       "      <td>Reeses Cups(Candy)   1 c. peanut butter 3/4 c....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  title  \\\n",
       "0           0    No-Bake Nut Cookies   \n",
       "1           1  Jewell Ball'S Chicken   \n",
       "2           2            Creamy Corn   \n",
       "3           3          Chicken Funny   \n",
       "4           4   Reeses Cups(Candy)     \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  [1 c. firmly packed brown sugar, 1/2 c. evapor...   \n",
       "1  [1 small jar chipped beef, cut up, 4 boned chi...   \n",
       "2  [2 (16 oz.) pkg. frozen corn, 1 (8 oz.) pkg. c...   \n",
       "3  [1 large whole chicken, 2 (10 1/2 oz.) cans ch...   \n",
       "4  [1 c. peanut butter, 3/4 c. graham cracker cru...   \n",
       "\n",
       "                                          directions  \\\n",
       "0  [In a heavy 2-quart saucepan, mix brown sugar,...   \n",
       "1  [Place chipped beef on bottom of baking dish.,...   \n",
       "2  [In a slow cooker, combine all ingredients. Co...   \n",
       "3  [Boil and debone chicken., Put bite size piece...   \n",
       "4  [Combine first four ingredients and press in 1...   \n",
       "\n",
       "                                              link  \\\n",
       "0   www.cookbooks.com/Recipe-Details.aspx?id=44874   \n",
       "1  www.cookbooks.com/Recipe-Details.aspx?id=699419   \n",
       "2   www.cookbooks.com/Recipe-Details.aspx?id=10570   \n",
       "3  www.cookbooks.com/Recipe-Details.aspx?id=897570   \n",
       "4  www.cookbooks.com/Recipe-Details.aspx?id=659239   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  [brown sugar, milk, vanilla, nuts, butter, bit...   \n",
       "1  [beef, chicken breasts, cream of mushroom soup...   \n",
       "2  [frozen corn, cream cheese, butter, garlic pow...   \n",
       "3  [chicken, chicken gravy, cream of mushroom sou...   \n",
       "4  [peanut butter, graham cracker crumbs, butter,...   \n",
       "\n",
       "                                        bag_of_words  \n",
       "0  No-Bake Nut Cookies 1 c. firmly packed brown s...  \n",
       "1  Jewell Ball'S Chicken 1 small jar chipped beef...  \n",
       "2  Creamy Corn 2 (16 oz.) pkg. frozen corn 1 (8 o...  \n",
       "3  Chicken Funny 1 large whole chicken 2 (10 1/2 ...  \n",
       "4  Reeses Cups(Candy)   1 c. peanut butter 3/4 c....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['bag_of_words'] = ''\n",
    "columns_list = ['title', 'ingredients', 'directions']\n",
    "for col in columns_list:\n",
    "    if col == 'title':\n",
    "        data['bag_of_words'] += data[col] + ' '\n",
    "    if col == 'ingredients':\n",
    "        data['bag_of_words'] += data[col].apply(' '.join) + ' '\n",
    "    if col == 'directions':\n",
    "        data['bag_of_words'] += data[col].apply(' '.join)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bag_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>No-Bake Nut Cookies 1 c. firmly packed brown s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>Jewell Ball'S Chicken 1 small jar chipped beef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>Creamy Corn 2 (16 oz.) pkg. frozen corn 1 (8 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>Chicken Funny 1 large whole chicken 2 (10 1/2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>Reeses Cups(Candy)   1 c. peanut butter 3/4 c....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title                                       bag_of_words\n",
       "0    No-Bake Nut Cookies  No-Bake Nut Cookies 1 c. firmly packed brown s...\n",
       "1  Jewell Ball'S Chicken  Jewell Ball'S Chicken 1 small jar chipped beef...\n",
       "2            Creamy Corn  Creamy Corn 2 (16 oz.) pkg. frozen corn 1 (8 o...\n",
       "3          Chicken Funny  Chicken Funny 1 large whole chicken 2 (10 1/2 ...\n",
       "4   Reeses Cups(Candy)    Reeses Cups(Candy)   1 c. peanut butter 3/4 c...."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_data = data[['title','bag_of_words']]\n",
    "bow_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          No-Bake Nut Cookies 1 c. firmly packed brown s...\n",
       "1          Jewell Ball'S Chicken 1 small jar chipped beef...\n",
       "2          Creamy Corn 2 (16 oz.) pkg. frozen corn 1 (8 o...\n",
       "3          Chicken Funny 1 large whole chicken 2 (10 1/2 ...\n",
       "4          Reeses Cups(Candy)   1 c. peanut butter 3/4 c....\n",
       "                                 ...                        \n",
       "1643093    Tuna 'N Egg Salad In Pitas 6 ounces tuna drain...\n",
       "1643094    Croque Monsieur Panini 2 tablespoons unsalted ...\n",
       "1643095    Croque Monsieur With Cucumber Salad 1/4 cup wh...\n",
       "1643096    Baked Pork Chops 1 egg whites 1 cup evaporated...\n",
       "1643097    Date Filled Oatmeal Cookies 8 ounces dates cut...\n",
       "Name: bag_of_words, Length: 1643098, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = bow_data.bag_of_words\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_document(document):\n",
    "    '''\n",
    "    Takes in a string.\n",
    "    Returns cleaned string.\n",
    "    '''\n",
    "    # lowercase the strings\n",
    "    doc_lower = document.lower() \n",
    "\n",
    "    #tokenize\n",
    "    tokens = word_tokenize(doc_lower) \n",
    "    \n",
    "    # remove punctuation\n",
    "    punc = set(string.punctuation)\n",
    "    tokens_no_punc = [word for word in tokens if word not in punc]\n",
    "   \n",
    "    # remove stopwords\n",
    "    s_words = set(stopwords.words('english'))\n",
    "    s_words_list = ['tablespoon', 'tbsp', 'teaspoon', 'tsp', 'cup', 'oz', 'lb', 'c.']\n",
    "    for word in s_words_list:\n",
    "        s_words.add(word)\n",
    "    tokens_no_sw = [word for word in tokens_no_punc if word not in s_words]\n",
    "    \n",
    "    # stem the words to get rid of multiple forms of the same word\n",
    "    porter = PS()\n",
    "    tokens_stemmed = [porter.stem(word) for word in tokens_no_sw]\n",
    "    \n",
    "    # join all words into one string\n",
    "    cleaned_doc = ' '.join(tokens_stemmed)\n",
    "    \n",
    "    return cleaned_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-943689c3e3f2>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bow_data['cleaned_bow'] = bow_data['bag_of_words'].apply(clean_document)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bag_of_words</th>\n",
       "      <th>cleaned_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No-Bake Nut Cookies</td>\n",
       "      <td>No-Bake Nut Cookies 1 c. firmly packed brown s...</td>\n",
       "      <td>no-bak nut cooki 1 firmli pack brown sugar 1/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jewell Ball'S Chicken</td>\n",
       "      <td>Jewell Ball'S Chicken 1 small jar chipped beef...</td>\n",
       "      <td>jewel ball 's chicken 1 small jar chip beef cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creamy Corn</td>\n",
       "      <td>Creamy Corn 2 (16 oz.) pkg. frozen corn 1 (8 o...</td>\n",
       "      <td>creami corn 2 16 pkg frozen corn 1 8 pkg cream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicken Funny</td>\n",
       "      <td>Chicken Funny 1 large whole chicken 2 (10 1/2 ...</td>\n",
       "      <td>chicken funni 1 larg whole chicken 2 10 1/2 ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reeses Cups(Candy)</td>\n",
       "      <td>Reeses Cups(Candy)   1 c. peanut butter 3/4 c....</td>\n",
       "      <td>rees cup candi 1 peanut butter 3/4 graham crac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643093</th>\n",
       "      <td>Tuna 'N Egg Salad In Pitas</td>\n",
       "      <td>Tuna 'N Egg Salad In Pitas 6 ounces tuna drain...</td>\n",
       "      <td>tuna n egg salad pita 6 ounc tuna drain 1 cook...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643094</th>\n",
       "      <td>Croque Monsieur Panini</td>\n",
       "      <td>Croque Monsieur Panini 2 tablespoons unsalted ...</td>\n",
       "      <td>croqu monsieur panini 2 tablespoon unsalt butt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643095</th>\n",
       "      <td>Croque Monsieur With Cucumber Salad</td>\n",
       "      <td>Croque Monsieur With Cucumber Salad 1/4 cup wh...</td>\n",
       "      <td>croqu monsieur cucumb salad 1/4 white wine vin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643096</th>\n",
       "      <td>Baked Pork Chops</td>\n",
       "      <td>Baked Pork Chops 1 egg whites 1 cup evaporated...</td>\n",
       "      <td>bake pork chop 1 egg white 1 evapor skim milk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643097</th>\n",
       "      <td>Date Filled Oatmeal Cookies</td>\n",
       "      <td>Date Filled Oatmeal Cookies 8 ounces dates cut...</td>\n",
       "      <td>date fill oatmeal cooki 8 ounc date cut small ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1643098 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0                        No-Bake Nut Cookies   \n",
       "1                      Jewell Ball'S Chicken   \n",
       "2                                Creamy Corn   \n",
       "3                              Chicken Funny   \n",
       "4                       Reeses Cups(Candy)     \n",
       "...                                      ...   \n",
       "1643093           Tuna 'N Egg Salad In Pitas   \n",
       "1643094               Croque Monsieur Panini   \n",
       "1643095  Croque Monsieur With Cucumber Salad   \n",
       "1643096                     Baked Pork Chops   \n",
       "1643097          Date Filled Oatmeal Cookies   \n",
       "\n",
       "                                              bag_of_words  \\\n",
       "0        No-Bake Nut Cookies 1 c. firmly packed brown s...   \n",
       "1        Jewell Ball'S Chicken 1 small jar chipped beef...   \n",
       "2        Creamy Corn 2 (16 oz.) pkg. frozen corn 1 (8 o...   \n",
       "3        Chicken Funny 1 large whole chicken 2 (10 1/2 ...   \n",
       "4        Reeses Cups(Candy)   1 c. peanut butter 3/4 c....   \n",
       "...                                                    ...   \n",
       "1643093  Tuna 'N Egg Salad In Pitas 6 ounces tuna drain...   \n",
       "1643094  Croque Monsieur Panini 2 tablespoons unsalted ...   \n",
       "1643095  Croque Monsieur With Cucumber Salad 1/4 cup wh...   \n",
       "1643096  Baked Pork Chops 1 egg whites 1 cup evaporated...   \n",
       "1643097  Date Filled Oatmeal Cookies 8 ounces dates cut...   \n",
       "\n",
       "                                               cleaned_bow  \n",
       "0        no-bak nut cooki 1 firmli pack brown sugar 1/2...  \n",
       "1        jewel ball 's chicken 1 small jar chip beef cu...  \n",
       "2        creami corn 2 16 pkg frozen corn 1 8 pkg cream...  \n",
       "3        chicken funni 1 larg whole chicken 2 10 1/2 ca...  \n",
       "4        rees cup candi 1 peanut butter 3/4 graham crac...  \n",
       "...                                                    ...  \n",
       "1643093  tuna n egg salad pita 6 ounc tuna drain 1 cook...  \n",
       "1643094  croqu monsieur panini 2 tablespoon unsalt butt...  \n",
       "1643095  croqu monsieur cucumb salad 1/4 white wine vin...  \n",
       "1643096  bake pork chop 1 egg white 1 evapor skim milk ...  \n",
       "1643097  date fill oatmeal cooki 8 ounc date cut small ...  \n",
       "\n",
       "[1643098 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_data['cleaned_bow'] = bow_data['bag_of_words'].apply(clean_document)\n",
    "bow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('./models/full_data_df_pickle_4.pkl', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('./models/full_data_df_pickle_5.pkl', protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_data.to_pickle('./models/training_df_pickle_4.pkl', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_data.to_pickle('./models/training_df_pickle_5.pkl', protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_cleaned = bow_data['cleaned_bow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1000\n",
    "ngram_range=(1,3)\n",
    "\n",
    "vec = CountVectorizer(max_df=0.85, \n",
    "                      min_df=10,\n",
    "                      ngram_range=ngram_range,\n",
    "                      max_features=num_features)\n",
    "\n",
    "tf = vec.fit_transform(docs_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_feature_names = vec.get_feature_names()\n",
    "# tf_feature_names[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [100]\n",
    "learning_method=['online']\n",
    "learning_offset = [10, 50, 90]\n",
    "doc_topic_prior = [None, 0.1, 0.9]\n",
    "topic_word_prior = [None, 0.1, 0.9]\n",
    "learning_decay = [0.5, 0.7, 0.9]\n",
    "batch_size = [64, 128]\n",
    "n_jobs= [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': [64, 128],\n",
      " 'doc_topic_prior': [None, 0.1, 0.9],\n",
      " 'learning_decay': [0.5, 0.7, 0.9],\n",
      " 'learning_method': ['online'],\n",
      " 'learning_offset': [10, 50, 90],\n",
      " 'n_components': [100],\n",
      " 'n_jobs': [-1],\n",
      " 'topic_word_prior': [None, 0.1, 0.9]}\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'n_components': num_topics,\n",
    "               'learning_method':learning_method,\n",
    "               'learning_offset': learning_offset,\n",
    "               'doc_topic_prior': doc_topic_prior,\n",
    "               'topic_word_prior': topic_word_prior,\n",
    "               'learning_decay': learning_decay,\n",
    "               'batch_size': batch_size,\n",
    "               'n_jobs': n_jobs}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train, tf_test = train_test_split(tf, test_size=0.25)\n",
    "lda = LatentDirichletAllocation()\n",
    "lda_grid = RandomizedSearchCV(estimator=lda, \n",
    "                              param_distributions=random_grid,\n",
    "                              cv=5,\n",
    "                              n_iter=10,\n",
    "                              n_jobs=-1, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "lda_grid.fit(tf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk space ran out... all 1000 GB..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame.from_dict(lda_grid.cv_results_))\n",
    "print('Test Score:', lda_grid.score(tf_test))\n",
    "print('Perplexity:', lda_grid.perplexity(tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model = lda_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_lda_model, './models/lda_model_full_tid_pickle4.joblib', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_lda_model, './models/lda_model_full_tid_pickle5.joblib', protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(vec, './models/vec_full_tid_pickle4.joblib', protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(vec, './models/vec_full_tid_pickle5.joblib', protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Model's Params: \", lda_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Model's Log Likelihood Score: \", lda_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Model's Perplexity: \", best_lda_model.perplexity(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-num_top_words - 1:-1]]))\n",
    "\n",
    "num_top_words = 10\n",
    "display_topics(lda, tf_feature_names, num_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_lda_model, './models/lda_model_full_tid.joblib')\n",
    "joblib.dump(vec, './models/vec_full_tid.joblib')\n",
    "lda = joblib.load('./models/lda_model_full_tid.joblib')\n",
    "tf_vectorizer = joblib.load('./models/vec_full_tid.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_recipes(keyword, recipes, probs, n_recipes=10):\n",
    "    idx_arr = np.array(recipes.index)\n",
    "    keyword_recipes = recipes[recipes.str.contains(keyword, case=False, regex=False)]\n",
    "    keyword_samples = np.random.choice(keyword_recipes.index, size=50, replace=True)\n",
    "    keyword_idxs = []\n",
    "    for sample_idx in keyword_samples:\n",
    "        keyword_idx = int(np.where(idx_arr == sample_idx)[0])\n",
    "        keyword_idxs.append(keyword_idx)\n",
    "\n",
    "    d={}\n",
    "    for idx in keyword_idxs:\n",
    "        sims = cosine_distances(probs[idx].reshape(1, -1), probs).argsort()[0]\n",
    "        for sim in sims[1:n_recipes+1]:\n",
    "            if sim not in d:\n",
    "                d[sim] = 1\n",
    "            else:\n",
    "                d[sim] += 1\n",
    "                \n",
    "    d_sorted = [k for k, v in sorted(d.items(), key=lambda item: item[1])][:-n_recipes:-1]\n",
    "    print(f'Top {n_recipes} recipes most closely related to {keyword}')\n",
    "    return np.array(recipes)[d_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = bow_toy_data.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_recipes('bean', recipes, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_recipes('vegan', recipes, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_recipes('pepperoni pizza', recipes, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_recipes('spaghetti', recipes, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_recipes('chicken soup', recipes, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to experiment with different parameters with the model, as well as the bag of words contents. First, let's see if we can identify the \"best\" number of topics using KMeans clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_recipes('lentil', recipes, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_recipes('cheese pizza', recipes, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "docs_vec = vectorizer.fit_transform(docs_cleaned)\n",
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=100\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "kmeans.fit(docs_vec)\n",
    "score = silhouette_score(docs_vec, kmeans.labels_)\n",
    "print(f'k = {k}, silhouette score = {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(kmeans, './models/kmeans_full.joblib')\n",
    "joblib.dump(vectorizer, './models/tf_vec_full.joblib')\n",
    "kmeans = joblib.load('./models/kmeans_full.joblib')\n",
    "tf_vec = joblib.load('./models/tf_vec_full.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the top 10 features for each cluster.\n",
    "n_features = 10\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-(n_features+1):-1]\n",
    "print(\"top features (words) for each cluster:\")\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    print(f\"{num}, {', '.join(features[i] for i in centroid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random sample of texts in each cluster \\n\")\n",
    "assigned_cluster = kmeans.transform(docs_vec).argmin(axis=1)\n",
    "for i in range(kmeans.n_clusters):\n",
    "    cluster = np.arange(0, docs_vec.shape[0])[assigned_cluster==i]\n",
    "    sample_recipes = np.random.choice(cluster, 10, replace=False)\n",
    "    \n",
    "    print(f'\\n cluster {i}:')\n",
    "    for idx in sample_recipes:\n",
    "        print(f'{recipes.iloc[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_count = []\n",
    "for i in range(kmeans.n_clusters):\n",
    "    cluster = np.arange(0, docs_vec.shape[0])[assigned_cluster==i]\n",
    "    recipe_count.append(len(cluster))\n",
    "    print(f\"Cluster {i}: {len(cluster)} recipes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = []\n",
    "n_features = 1\n",
    "top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-(n_features+1):-1]\n",
    "for num, centroid in enumerate(top_centroids):\n",
    "    top_words.append(', '.join(features[i] for i in centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 8))\n",
    "ax.set_title('Recipe Count By Cluster', fontsize = 24)\n",
    "ax.set_ylabel('Count', fontsize = 24)\n",
    "plt.yticks(fontsize = 20)\n",
    "ax.set_xticklabels(top_words, fontsize = 18, rotation = 90)\n",
    "ax.bar(top_words, recipe_count);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
